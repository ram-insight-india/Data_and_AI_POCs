{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMhUPlMybBPK"
      },
      "source": [
        "# Download Latest Immigration Enforcement Data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cBP7AM4dbBPL",
        "outputId": "ef34b552-d89f-401e-cb2c-f5a2b4eef783"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.33.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: urllib3~=2.4.0 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]~=2.4.0->selenium) (2.4.0)\n",
            "Collecting trio~=0.30.0 (from selenium)\n",
            "  Downloading trio-0.30.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket~=0.12.2 (from selenium)\n",
            "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: certifi>=2025.4.26 in /usr/local/lib/python3.11/dist-packages (from selenium) (2025.6.15)\n",
            "Collecting typing_extensions~=4.13.2 (from selenium)\n",
            "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: websocket-client~=1.8.0 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
            "Collecting outcome (from trio~=0.30.0->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (1.3.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.12.2->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]~=2.4.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n",
            "Downloading selenium-4.33.0-py3-none-any.whl (9.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio-0.30.0-py3-none-any.whl (499 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.2/499.2 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
            "Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: wsproto, typing_extensions, outcome, trio, trio-websocket, selenium\n",
            "  Attempting uninstall: typing_extensions\n",
            "    Found existing installation: typing_extensions 4.14.0\n",
            "    Uninstalling typing_extensions-4.14.0:\n",
            "      Successfully uninstalled typing_extensions-4.14.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "typeguard 4.4.3 requires typing_extensions>=4.14.0, but you have typing-extensions 4.13.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed outcome-1.3.0.post0 selenium-4.33.0 trio-0.30.0 trio-websocket-0.12.2 typing_extensions-4.13.2 wsproto-1.2.0\n"
          ]
        }
      ],
      "source": [
        "!python -m pip install selenium beautifulsoup4 pandas requests openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###----Necessary Libraries----###\n",
        "\n",
        "import time\n",
        "import re\n",
        "import os\n",
        "import requests\n",
        "import pandas as pd\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.by import By\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "ctts8JGZdmx8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def configure_browser_options():\n",
        "    \"\"\"Configures Chrome options for headless Browse.\"\"\"\n",
        "    chrome_options = Options()\n",
        "    chrome_options.add_argument('--headless')\n",
        "    chrome_options.add_argument('--no-sandbox')\n",
        "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "    return chrome_options\n",
        "\n",
        "def get_page_content(url):\n",
        "    \"\"\"Fetches the content of a web page using Selenium.\"\"\"\n",
        "    browser_options = configure_browser_options()\n",
        "    driver = webdriver.Chrome(options=browser_options)\n",
        "    try:\n",
        "        driver.get(url)\n",
        "        time.sleep(5)  # Allow time for the page to load\n",
        "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "        time.sleep(5)  # Allow time for scrolling\n",
        "        page_source = driver.page_source\n",
        "    finally:\n",
        "        driver.quit()\n",
        "    return page_source\n",
        "\n",
        "def extract_download_links(html_content):\n",
        "    \"\"\"Extracts download links for spreadsheet and CSV files from HTML.\"\"\"\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "    all_links = soup.find_all('a', href=True)\n",
        "\n",
        "    file_links = []\n",
        "    for link in all_links:\n",
        "        href = link['href']\n",
        "        text = link.text.strip()\n",
        "        if re.search(r'\\.(xlsx?|csv|xls)$', href, re.IGNORECASE):\n",
        "            file_links.append((href, text))\n",
        "    return file_links\n",
        "\n",
        "def get_latest_file_info(links):\n",
        "    \"\"\"Sorts links by date and returns the latest file's URL and label.\"\"\"\n",
        "    def extract_date_key(text_or_url):\n",
        "        match = re.search(r'(\\d{4}[-_]\\d{2})', text_or_url)\n",
        "        return match.group(1) if match else text_or_url\n",
        "\n",
        "    links.sort(key=lambda x: extract_date_key(x[0]), reverse=True)\n",
        "\n",
        "    latest_suffix, latest_label = links[0]\n",
        "\n",
        "    # Construct full URL if it's a relative path\n",
        "    base_domain = \"https://ohss.dhs.gov\"\n",
        "    full_url = f\"{base_domain}{latest_suffix}\" if latest_suffix.startswith('/') else latest_suffix\n",
        "\n",
        "    return full_url, latest_label\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "u3IgjuhMda2U"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_file(url, destination_folder=\".\"):\n",
        "    \"\"\"Downloads a file from a given URL.\"\"\"\n",
        "    file_ext = url.split('.')[-1]\n",
        "    local_filename = os.path.join(destination_folder, f\"latest_data.{file_ext}\")\n",
        "\n",
        "    print(f\"Attempting to download: {url}\")\n",
        "    response = requests.get(url, stream=True)\n",
        "    response.raise_for_status()  # Raise an exception for bad status codes\n",
        "\n",
        "    with open(local_filename, 'wb') as f:\n",
        "        for chunk in response.iter_content(chunk_size=8192):\n",
        "            f.write(chunk)\n",
        "\n",
        "    print(f\"File downloaded to: {local_filename}\")\n",
        "    return local_filename, file_ext"
      ],
      "metadata": {
        "id": "SM5TrBaneCbD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_to_dataframe(filepath, file_type):\n",
        "    \"\"\"Loads data from a file into a pandas DataFrame based on file type.\"\"\"\n",
        "    if file_type in ['xlsx', 'xls']:\n",
        "        df = pd.read_excel(filepath)\n",
        "    elif file_type == 'csv':\n",
        "        df = pd.read_csv(filepath)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format provided.\")\n",
        "    return df\n",
        "\n",
        "def main():\n",
        "    target_url = \"https://ohss.dhs.gov/topics/immigration/immigration-enforcement/monthly-tables\"\n",
        "\n",
        "    print(\"Fetching page content...\")\n",
        "    page_content = get_page_content(target_url)\n",
        "\n",
        "    print(\"Extracting download links...\")\n",
        "    found_links = extract_download_links(page_content)\n",
        "\n",
        "    if not found_links:\n",
        "        print(\"No downloadable files found.\")\n",
        "        return\n",
        "\n",
        "    print(\"Identifying the most recent file...\")\n",
        "    latest_file_url, file_label = get_latest_file_info(found_links)\n",
        "    print(f\"Most recent file identified: {file_label} from {latest_file_url}\")\n",
        "\n",
        "    try:\n",
        "        downloaded_filepath, downloaded_file_ext = download_file(latest_file_url)\n",
        "\n",
        "        print(\"Loading data into DataFrame...\")\n",
        "        data_df = load_data_to_dataframe(downloaded_filepath, downloaded_file_ext)\n",
        "\n",
        "        print(\"\\nSuccessfully loaded data. Here's a preview:\")\n",
        "        print(data_df.head())\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error during file download: {e}\")\n",
        "    except ValueError as e:\n",
        "        print(f\"Data loading error: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zQa2qoWeHSL",
        "outputId": "d5a67f50-b495-45cf-ef1c-02e528d56e34"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching page content...\n",
            "Extracting download links...\n",
            "Identifying the most recent file...\n",
            "Most recent file identified: Immigration Enforcement and Legal Processes Monthly Tables - November 2024 from https://ohss.dhs.gov/sites/default/files/2025-01/2025_0116_ohss_immigration-enforcement-and-legal-processes-tables-november-2024.xlsx\n",
            "Attempting to download: https://ohss.dhs.gov/sites/default/files/2025-01/2025_0116_ohss_immigration-enforcement-and-legal-processes-tables-november-2024.xlsx\n",
            "File downloaded to: ./latest_data.xlsx\n",
            "Loading data into DataFrame...\n",
            "\n",
            "Successfully loaded data. Here's a preview:\n",
            "                   Table of Contents  \\\n",
            "0                                NaN   \n",
            "1  Click link for corresponding tab:   \n",
            "2                                NaN   \n",
            "3                           Category   \n",
            "4                         Encounters   \n",
            "\n",
            "                                          Unnamed: 1     Unnamed: 2  \n",
            "0                                                NaN            NaN  \n",
            "1                                                NaN            NaN  \n",
            "2                                                NaN            NaN  \n",
            "3                                              Table  Starting Date  \n",
            "4  Nationwide CBP Encounters by Encounter Type an...           2014  \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}